{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12760370,"sourceType":"datasetVersion","datasetId":8066456},{"sourceId":12760417,"sourceType":"datasetVersion","datasetId":8066490}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Cell 1: Core LangChain\n!pip install -q langchain\n!pip install torch gc\n\n# Cell 2: LangChain integrations\n!pip install -q langchain-community langchain-huggingface langchain-chroma langchain_google_genai langchain_experimental\n\n# Cell 3: ML libraries\n!pip install -q sentence-transformers transformers chromadb\n\n# Cell 4: Utilities\n!pip install -q python-dotenv torch unstructured","metadata":{"execution":{"iopub.status.busy":"2025-08-18T23:58:21.519032Z","iopub.execute_input":"2025-08-18T23:58:21.519432Z","iopub.status.idle":"2025-08-18T23:58:37.273617Z","shell.execute_reply.started":"2025-08-18T23:58:21.519407Z","shell.execute_reply":"2025-08-18T23:58:37.272540Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n\u001b[31mERROR: Could not find a version that satisfies the requirement gc (from versions: none)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for gc\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from langchain_community.document_loaders import DirectoryLoader\nfrom langchain_community.chat_models import ChatOllama\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain_chroma import Chroma\nfrom langchain_huggingface import HuggingFaceEmbeddings\nfrom langchain_google_genai import GoogleGenerativeAIEmbeddings  \nfrom langchain_experimental.text_splitter import SemanticChunker\nimport os\nimport shutil\n\nimport json\nfrom langchain_huggingface import HuggingFacePipeline\nfrom transformers import pipeline\nimport os\nfrom pathlib import Path\nimport torch\nimport gc\nimport warnings","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2025-08-18T23:58:37.274683Z","iopub.execute_input":"2025-08-18T23:58:37.274962Z","iopub.status.idle":"2025-08-18T23:58:47.366602Z","shell.execute_reply.started":"2025-08-18T23:58:37.274933Z","shell.execute_reply":"2025-08-18T23:58:47.365799Z"},"trusted":true},"outputs":[{"name":"stderr","text":"2025-08-18 23:58:42.403998: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1755561522.427114     192 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1755561522.434367     192 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"class DatabaseManager:\n    def __init__(self, embedding_model_name=\"sentence-transformers/all-MiniLM-L12-v2\", \n                 embedding_model_type=\"huggingface\"):\n        \"\"\"\n        Initialize DatabaseManager with specified embedding model.\n        \n        Args:\n            embedding_model_name: Name of the embedding model\n            embedding_model_type: Type of model (\"huggingface\" or \"gemini\")\n        \"\"\"\n        self.embedding_model_name = embedding_model_name\n        self.embedding_model_type = embedding_model_type\n        \n        # Initialize embedding function based on type\n        if embedding_model_type == \"gemini\":\n            api_key = os.getenv(\"GEMINI_API_KEY\")  # Changed from GEMINI_API_KEY\n            if not api_key:\n                raise ValueError(\"GEMINI_API_KEY environment variable is required for Gemini models\")\n            \n            # Extract model name (remove 'gemini/' prefix)\n            model_name = self.embedding_model_name.replace(\"gemini/\", \"\")\n            self.embedding_function = GoogleGenerativeAIEmbeddings(\n                model=model_name,\n                google_api_key=api_key\n            )\n        elif embedding_model_type == \"huggingface\":\n            self.embedding_function = HuggingFaceEmbeddings(model_name=embedding_model_name)\n        else:  # huggingface\n            embedding_model_type == \"huggingface\"\n            self.embedding_function = HuggingFaceEmbeddings(model_name=embedding_model_name)\n        \n        print(f\"Initialized {embedding_model_type} embedding model: {embedding_model_name}\")\n\n    # Rest of your DatabaseManager methods remain the same...\n    def load_documents(self, data_path):\n        \"\"\"Load documents from the specified directory.\"\"\"\n        try:\n            loader = DirectoryLoader(data_path, glob=\"*.md\")\n            documents = loader.load()\n            # print(f\"Loaded {len(documents)} documents from {data_path}\")\n            return documents\n        except Exception as e:\n            print(f\"Error loading documents: {e}\")\n            return []\n\n    def split_text(self, documents):\n        \"\"\"Split documents into chunks.\"\"\"\n        try:\n            text_splitter = RecursiveCharacterTextSplitter(\n                chunk_size=500,\n                chunk_overlap=150,\n                length_function=len,\n                add_start_index=True,\n            )\n            chunks = text_splitter.split_documents(documents)\n            # print(f\"Split into {len(chunks)} chunks\")\n            return chunks\n        except Exception as e:\n            print(f\"Error splitting text: {e}\")\n            return []\n\n    def save_to_chroma(self, chunks, persist_directory):\n        \"\"\"Save document chunks to Chroma database.\"\"\"\n        try:\n            # Create directory if it doesn't exist\n            os.makedirs(persist_directory, exist_ok=True)\n            \n            db = Chroma.from_documents(\n                chunks, \n                self.embedding_function, \n                persist_directory=persist_directory\n            )\n            # print(f\"Saved {len(chunks)} chunks to Chroma database at {persist_directory}\")\n            return db\n        except Exception as e:\n            print(f\"Error saving to Chroma: {e}\")\n            return None\n\n    def generate_data_store(self, data_path=\"books\", persist_directory=\"chroma\"):\n        \"\"\"Complete pipeline: load documents, split text, and save to database.\"\"\"\n        # print(f\"Starting data store generation...\")\n        # print(f\"Data path: {data_path}\")\n        # print(f\"Persist directory: {persist_directory}\")\n        print(f\"Embedding model: {self.embedding_model_name} ({self.embedding_model_type})\")\n        \n        # Load documents\n        documents = self.load_documents(data_path)\n        if not documents:\n            return False\n        \n        # Split into chunks\n        chunks = self.split_text(documents)\n        if not chunks:\n            return False\n        \n        # Save to database\n        db = self.save_to_chroma(chunks, persist_directory)\n        return db is not None","metadata":{"execution":{"iopub.status.busy":"2025-08-18T23:58:47.367495Z","iopub.execute_input":"2025-08-18T23:58:47.368016Z","iopub.status.idle":"2025-08-18T23:58:47.377855Z","shell.execute_reply.started":"2025-08-18T23:58:47.367985Z","shell.execute_reply":"2025-08-18T23:58:47.377146Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"class QueryEngine:\n    def __init__(self, persist_directory=\"chroma\", \n                 embedding_model_name=\"sentence-transformers/all-MiniLM-L12-v2\",\n                 embedding_model_type=\"huggingface\",\n                 text_model_name=\"google/flan-t5-base\"):\n        \"\"\"\n        Initialize QueryEngine with specified models.\n        \n        Args:\n            persist_directory: Path to the Chroma database\n            embedding_model_name: Name of the embedding model\n            embedding_model_type: Type of embedding model (\"huggingface\" or \"gemini\")\n            text_model_name: Name of the text generation model\n        \"\"\"\n        self.persist_directory = persist_directory\n        self.embedding_model_name = embedding_model_name\n        self.embedding_model_type = embedding_model_type\n        self.text_model_name = text_model_name\n        \n        # Initialize embedding function based on type\n        if embedding_model_type == \"gemini\":\n            api_key = os.getenv(\"GEMINI_API_KEY\")  # Changed from GEMINI_API_KEY\n            if not api_key:\n                raise ValueError(\"GEMINI_API_KEY environment variable is required for Gemini models\")\n            \n            # Extract model name (remove 'gemini/' prefix)\n            model_name = self.embedding_model_name.replace(\"gemini/\", \"\")\n            self.embedding_function = GoogleGenerativeAIEmbeddings(\n                model=model_name,\n                google_api_key=api_key\n            )\n        elif embedding_model_type == \"huggingface\":\n            self.embedding_function = HuggingFaceEmbeddings(model_name=embedding_model_name)\n        else:  # huggingface\n            embedding_model_type == \"huggingface\"\n            self.embedding_function = HuggingFaceEmbeddings(model_name=embedding_model_name)\n        \n        # Initialize text generation model\n        if self.text_model_name.startswith(\"google/flan\"):\n            self.hf_pipeline = pipeline(\n                \"text2text-generation\",\n                model=self.text_model_name,\n                max_length=512,\n            )\n        elif self.text_model_name.startswith(\"mistralai/\"):\n            self.hf_pipeline = pipeline(\n                \"text-generation\",  # Mistral uses text-generation\n                model=self.text_model_name,\n                max_new_tokens=100,     # Limit output length\n                do_sample=True,\n                temperature=0.3,        # Lower temp for more focused answers\n                pad_token_id=2,         # Mistral's pad token\n                truncation=True,\n                return_full_text=False, # Only return generated text\n                device=-1               # Force CPU for stability\n            )\n        elif self.text_model_name.startswith(\"gpt\") or self.text_model_name.startswith(\"distilgpt\"):\n            # Special handling for GPT-2 models to fix the token length issue\n            self.hf_pipeline = pipeline(\n                \"text-generation\",\n                model=self.text_model_name,\n                max_new_tokens=50,         # Generate only 50 new tokens\n                do_sample=True,\n                temperature=0.7,\n                pad_token_id=50256,\n                truncation=True,           # Truncate long inputs\n                return_full_text=False,    # Only return generated text, not input\n                device=-1                  # Force CPU for stability\n            )\n        else:\n            self.text_model_name = \"google/flan-t5-large\"\n            self.hf_pipeline = pipeline(\n                \"text2text-generation\",\n                model=self.text_model_name,\n                max_length=512,\n            )\n        \n        self.model = HuggingFacePipeline(pipeline=self.hf_pipeline)\n        \n        # Initialize database\n        self.db = Chroma(persist_directory=persist_directory, \n                        embedding_function=self.embedding_function)\n    \n        self.PROMPT_TEMPLATE = \"\"\"\n        You are answering questions about Alice in Wonderland based on the provided context.\n\n        CONTEXT:\n        {context}\n        \n        QUESTION: {question}\n        \n        OPTIONS:\n        {options}\n        \n        INSTRUCTIONS:\n        - Read the context carefully\n        - Answer based ONLY on the information provided in the context.\n        - Respond with ONLY the letter (A, B, C, or D) of the correct answer\n        - Do not include explanations or sources\n        \"\"\"\n            # \"\"\"\n            # Answer the question based only on the following context:\n\n            # {context}\n\n            # ---\n\n            # Answer the question based on the above context: {question}\n            # here are the options:\n            # {options}\n\n            # Respond only the Letter of the correct options like A, B, C and D. Do not inlcude the source.\n            # \"\"\"\n        # prompt 2: \n\n        # prompt 3: \n        # \"\"\"\n        # <s>[INST] You are answering questions about Alice in Wonderland. \n\n        # Context: {context_text}\n        # Question: {question}\n        # Options: {options_text}\n        \n        # INSTRUCTIONS:\n        # - Read the context carefully\n        # - Answer based ONLY on the information provided in the context.\n        # - Respond with ONLY the letter (A, B, C, or D) of the correct answer\n        # - Do not include explanations or sources\n        # [/INST]\"\"\"\n        \n        # print(f\"QueryEngine initialized:\")\n        # print(f\"  Embedding: {embedding_model_name} ({embedding_model_type})\")\n        # print(f\"  Text Generation: {text_model_name}\")\n        # print(f\"  Database: {persist_directory}\")\n        print(f\"Initialized {embedding_model_type} embedding model: {embedding_model_name} with chat model : {text_model_name}\")\n\n    # Rest of your QueryEngine methods remain the same...\n    \n    def load_quiz_data(self, quiz_file_path='test_questions.json'):\n        \"\"\"Load quiz data from JSON file.\"\"\"\n        try:\n            with open(quiz_file_path, 'r', encoding='utf-8') as file:\n                data = json.load(file)\n                # print(f\"Loaded {len(data)} questions from {quiz_file_path}\")\n                return data\n        except FileNotFoundError:\n            print(f\"Error: {quiz_file_path} file not found!\")\n            return []\n        except json.JSONDecodeError as e:\n            print(f\"Error parsing JSON: {e}\")\n            return []\n \n    def semantic_search_database(self, query, k=5):\n        \"\"\"Search the database for relevant documents.\"\"\"\n        if self.db is None:\n            return []\n        \n        try:\n            results = self.db.similarity_search_with_relevance_scores(query, k=k)\n            return results\n        except Exception as e:\n            print(f\"Error searching database: {e}\")\n            return []\n    \n    def filter_response(self, response):\n        edit_response = response.replace('-', '').strip()\n        return edit_response\n\n    def generate_response(self, question, options, context_text):\n        \"\"\"Generate a response using the LLM.\"\"\"\n        # Format the prompt\n        options_text = \"\\n\".join(options) if isinstance(options, list) else str(options)\n        prompt = self.PROMPT_TEMPLATE.format(\n            context=context_text, \n            question=question, \n            options=options_text\n        )\n        \n        try:\n            # Use the HuggingFace model to generate response\n            response_text = self.model.invoke(prompt)\n            response_text = self.filter_response(response_text)\n            return response_text\n        except Exception as e:\n            print(f\"Error generating response: {e}\")\n            return \"Error generating response.\"\n    \n    def query_single_question(self, question, options=None, show_context=False):\n        \"\"\"Query a single question and return the response.\"\"\"\n        # Search the database\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\", UserWarning)\n        results = self.semantic_search_database(question, k=5)\n        \n        if not results:\n            return {\n                'question': question,\n                'response': 'No relevant context found.',\n                'context': '',\n                'sources': []\n            }\n        \n        # Prepare context from search results\n        context_text = \"\\n\\n---\\n\\n\".join([doc.page_content for doc, _score in results])\n        # sources = [doc.metadata.get(\"source\", \"Unknown\") for doc, _score in results]\n        sources = [(_score, doc.metadata.get(\"source\", \"Unknown\"), doc.page_content) for doc, _score in results]\n        all_scores = [_score for doc, _score in results]\n        avg = sum(all_scores) / len(all_scores) if all_scores else 0\n\n        \n        # Generate response\n        response_text = self.generate_response(question, options or [], context_text)\n        \n        result = {\n            'question': question,\n            'response': response_text.replace('-', '').strip(),\n            'sources': sources,\n            \"avg relevance sources\" : avg\n        }\n        \n        if show_context:\n            result['context'] = context_text\n        \n        return result\n    \n    def run_quiz(self, quiz_file_path='test_questions.json', show_details=False, limit=None):\n        \"\"\"Run the complete quiz and return results.\"\"\"\n        # Load quiz data\n        quiz_data = self.load_quiz_data(quiz_file_path)\n        \n        if not quiz_data:\n            print(f\"No quiz data loaded. quiz_file_path = {quiz_file_path} Exiting.\")\n            return []\n        \n        # Limit questions if specified\n        if limit:\n            quiz_data = quiz_data[:limit]\n            # print(f\"Running quiz with {limit} questions.\")\n        \n        results = []\n        correct_count = 0\n        \n        for i, question_data in enumerate(quiz_data, 1):\n            # print(f\"Question {i} of {len(quiz_data)}\")\n            \n            question_id = question_data.get(\"id\", i)\n            question = question_data[\"question\"]\n            options = question_data[\"options\"]\n            correct_answer = question_data[\"answer\"]\n            \n            # Query the database and generate response\n            result = self.query_single_question(question, options, show_context=False)\n            \n            # Add quiz-specific information\n            result.update({\n                'id': question_id,\n                'options': options,\n                'correct_answer': correct_answer,\n                'response' : result['response'],\n                'is_correct': result['response'].strip().upper() == correct_answer.upper()\n            })\n\n            if result[\"is_correct\"] == False and len(result[\"response\"]) != 1:\n                if result[\"correct_answer\"].upper().strip() == \"A\":\n                    alternate_correct_answer = result[\"options\"][0][4:].replace('-', '').strip()\n                elif result[\"correct_answer\"].upper().strip() == \"B\":\n                    alternate_correct_answer = result[\"options\"][1][4:].replace('-', '').strip()\n                elif result[\"correct_answer\"].upper().strip() == \"C\":\n                    alternate_correct_answer = result[\"options\"][2][4:].replace('-', '').strip()\n                elif result[\"correct_answer\"].upper().strip() == \"D\":\n                    alternate_correct_answer = result[\"options\"][3][4:].replace('-', '').strip()\n                else:\n                    alternate_correct_answer = \"\"\n\n                if alternate_correct_answer.upper() == result[\"response\"].upper():\n                    result[\"is_correct\"] = True\n                else:\n                    if result[\"response\"].upper().startswith(alternate_correct_answer.upper()):\n                        result[\"response\"] = alternate_correct_answer\n                        result[\"is_correct\"] = True\n                    else:\n                        result[\"is_correct\"] = False\n\n            if result['is_correct']:\n                correct_count += 1\n            \n            results.append(result)\n            \n            # Show details if requested\n            if show_details:\n                print(\"=\" * 50)\n                print(f\"Question {question_id}: {question}\")\n                for j, option in enumerate(options, 1):\n                    print(f\"  {option}\")\n                print(f\"AI Response: {result['response']}\")\n                print(f\"Correct Answer: {correct_answer}\")\n                print(f\"Result: {'‚úì Correct' if result['is_correct'] else '‚úó Incorrect'}\")\n                print()\n        \n        # Summary\n        accuracy = (correct_count / len(quiz_data)) * 100 if quiz_data else 0\n        print(f\"\\nQuiz Summary:\")\n        print(f\"Correct Answers: {correct_count} / {len(quiz_data)}. Accuracy: {accuracy:.1f}%\")\n        \n        return results\n    \n    def set_prompt_template(self, new_template):\n        \"\"\"Set a custom prompt template.\"\"\"\n        self.PROMPT_TEMPLATE = new_template\n","metadata":{"execution":{"iopub.status.busy":"2025-08-18T23:58:47.379916Z","iopub.execute_input":"2025-08-18T23:58:47.380125Z","iopub.status.idle":"2025-08-18T23:58:47.410065Z","shell.execute_reply.started":"2025-08-18T23:58:47.380108Z","shell.execute_reply":"2025-08-18T23:58:47.409461Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":"EMBEDDING_MODEL_OPTIONS = [\n    \"sentence-transformers/all-MiniLM-L6-v2\", # success\n    \"sentence-transformers/all-mpnet-base-v2\", # success\n    \"BAAI/bge-m3\",\n    \"BAAI/bge-large-en\", # success\n    \"BAAI/bge-base-en-v1.5\",\n    \"BAAI/bge-large-en-v1.5\",\n    \"intfloat/e5-base-v2\", # success\n    \"sentence-transformers/static-retrieval-mrl-en-v1\", # success\n    \"sentence-transformers/all-MiniLM-L12-v2\", # success # best one so far\n    # \"gemini/embedding-001\",       # Older Gemini model # horrible\n    # \"gemini/text-embedding-005\",  # New Gemini model\n    \"nomic-ai/nomic-embed-text-v1.5\",\n    \"sentence-transformers/multi-qa-mpnet-base-dot-v1\",\n    \"sentence-transformers/multi-qa-mpnet-base-cos-v1\",\n    \"hkunlp/instructor-large\",\n    \"hkunlp/instructor-xl\"\n]\n\nTEXT_GENERATION_MODEL_OPTIONS = [\n    \"google/flan-t5-small\",\n    \"google/flan-t5-base\", # have been using this for default development testing\n    \"google/flan-t5-large\",\n    \"google/flan-t5-xl\",\n    \"tiiuae/falcon-7b\",\n    \"tiiuae/Falcon-H1-0.5B-Instruct\",\n    \"tiiuae/falcon-7b-instruct\",\n    # \"mistralai/Mistral-7B-Instruct-v0.3\", # not free\n    # \"mistralai/Mistral-7B-Instruct-v0.2\", # not free\n    # \"mistralai/Mistral-Small-3.2-24B-Instruct-2506\", # not free\n    \"HuggingFaceH4/zephyr-7b-beta\",\n    \"google/gemma-3-1b-it\",\n    \"google/gemma-2-2b\",\n    \"google/gemma-2-2b-it\",\n    \"meta-llama/Llama-3.1-8B-Instruct\",\n    \"meta-llama/Llama-3.2-3B-Instruct\",\n    \"meta-llama/Meta-Llama-3-8B-Instruct\",\n    \"meta-llama/Llama-3.2-1B\",\n    # \"gpt2\",\n    # \"distilgpt2\",\n]\n\n# Fixed model types to match all embedding models (all are HuggingFace)\nEMBEDDING_MODEL_TYPES = [\n    \"huggingface\",  # 0 - all-MiniLM-L6-v2\n    \"huggingface\",  # 1 - all-mpnet-base-v2\n    \"huggingface\",  # 2 - bge-m3\n    \"huggingface\",  # 3 - bge-large-en\n    \"huggingface\",  # 4 - bge-base-en-v1.5\n    \"huggingface\",  # 5 - bge-large-en-v1.5\n    \"huggingface\",  # 6 - e5-base-v2 (Fixed from \"gemini\")\n    \"huggingface\",  # 7 - static-retrieval-mrl-en-v1\n    \"huggingface\",  # 8 - all-MiniLM-L12-v2 (Your best!)\n    \"huggingface\",  # 9 - nomic-embed-text-v1.5\n    \"huggingface\",  # 10 - multi-qa-mpnet-base-dot-v1\n    \"huggingface\",  # 11 - multi-qa-mpnet-base-cos-v1\n    \"huggingface\",  # 12 - instructor-large\n    \"huggingface\",  # 13 - instructor-xl\n]","metadata":{"execution":{"iopub.status.busy":"2025-08-18T23:58:47.410835Z","iopub.execute_input":"2025-08-18T23:58:47.411028Z","iopub.status.idle":"2025-08-18T23:58:47.429028Z","shell.execute_reply.started":"2025-08-18T23:58:47.411013Z","shell.execute_reply":"2025-08-18T23:58:47.428353Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def list_models():\n    \"\"\"List all available models.\"\"\"\n    print(\"Available Embedding Models:\")\n    for i, (model, model_type) in enumerate(zip(EMBEDDING_MODEL_OPTIONS, EMBEDDING_MODEL_TYPES)):\n        print(f\"  {i}: {model} ({model_type})\")\n    \n    print(\"\\nAvailable Text Generation Models:\")\n    for i, model in enumerate(TEXT_GENERATION_MODEL_OPTIONS):\n        print(f\"  {i}: {model}\")\n        \ndef clear_cuda_memory():\n    \"\"\"Clear CUDA memory and run garbage collection.\"\"\"\n    \n    \n    if torch.cuda.is_available():\n        # print(\"üßπ Clearing CUDA memory...\")\n        torch.cuda.empty_cache()\n        torch.cuda.synchronize()\n        # print(f\"üíæ GPU Memory before cleanup: {torch.cuda.memory_allocated()/1024**3:.2f} GB\")\n        \n        # Force garbage collection\n        gc.collect()\n        \n        # Clear cache again after garbage collection\n        torch.cuda.empty_cache()\n        \n        # print(f\"‚úÖ GPU Memory after cleanup: {torch.cuda.memory_allocated()/1024**3:.2f} GB\")\n        # print(f\"üìä GPU Memory cached: {torch.cuda.memory_reserved()/1024**3:.2f} GB\")\n    else:\n        # print(\"üñ•Ô∏è  No CUDA device available - running on CPU\")\n        # Still run garbage collection for CPU\n        gc.collect()\n        \ndef main(mode=\"create\", embedding_model_index=0, text_generation_model_index=-1, save_result=1):\n    clear_cuda_memory()\n    embedding_model_index = embedding_model_index\n    \n    raw_knowledge_directory = \"/kaggle/input/text-for-summarizing/books\"\n    test_questions_directory = \"/kaggle/input/test-questions/test_questions.json\"\n    \n    os.makedirs(\"chroma\", exist_ok=True)\n    os.makedirs(\"quiz_results\", exist_ok=True)\n    \n    # Get selected models\n    embedding_model = EMBEDDING_MODEL_OPTIONS[embedding_model_index]\n    embedding_model_type = EMBEDDING_MODEL_TYPES[embedding_model_index]\n    \n    db_data_path = f\"chroma/{embedding_model.split('/')[-1].replace('/', '_').replace('-', '_')}\"\n    print(f\"Using embedding model: {embedding_model} ({embedding_model_type})\")\n    \n    if text_generation_model_index != -1:\n        text_model = TEXT_GENERATION_MODEL_OPTIONS[text_generation_model_index]\n        result_file_path = f\"quiz_results/{embedding_model.split('/')[-1].replace('/', '_').replace('-', '_')}--{text_model.split('/')[-1].replace('/', '_').replace('-', '_')}_quiz_results.json\"\n        print(f\"Using text generation model: {text_model}\")\n    \n    \n    \n    \n    def create_mode():\n        db_manager = DatabaseManager(embedding_model_name=embedding_model, \n                                   embedding_model_type=embedding_model_type)\n        success = db_manager.generate_data_store(data_path=raw_knowledge_directory, \n                                                persist_directory=db_data_path)\n\n    def quiz_mode():\n        print(\"Running Alice in Wonderland quiz...\")\n        query_engine = QueryEngine(persist_directory=db_data_path,\n                                 embedding_model_name=embedding_model,\n                                 embedding_model_type=embedding_model_type,\n                                 text_model_name=text_model)\n        \n        # Run the quiz\n        results = query_engine.run_quiz(test_questions_directory)\n        \n        # Rest of quiz_mode code remains the same...\n        if results:\n            print(\"\\n\" + \"=\"*50)\n            # print(\"DETAILED ANALYSIS\")\n            # print(\"=\"*50)\n            # print(\"Embedding Model:\", embedding_model)\n            # print(\"Text Generation Model:\", text_model)\n    \n            # correct_results = [r for r in results if r['is_correct']]\n            # incorrect_results = [r for r in results if not r['is_correct']]\n            \n            # if incorrect_results:\n            #     print(f\"\\nIncorrect answers ({len(incorrect_results)}):\")\n            #     for result in incorrect_results:\n            #         print(f\"Q{result['id']}: Expected {result['correct_answer']}, got {result['response']}\")\n            \n            # if correct_results:\n            #     print(f\"\\nCorrect answers: {len(correct_results)}\")\n\n            if save_result==1:\n                with open(result_file_path, \"w\") as f:\n                    json.dump(results, f, indent=4)\n            # print(f\"Quiz results saved to {result_file_path}\")\n    if mode==\"create\":\n        create_mode()\n    elif mode==\"quiz\":\n        quiz_mode()\n    clear_cuda_memory()\ndef clear_specific_model_cache(model_name):\n    \"\"\"Clear cache for a specific model.\"\"\"\n    import shutil\n    from pathlib import Path\n    \n    # Convert model name to cache-safe format\n    safe_model_name = model_name.replace(\"/\", \"--\")\n    \n    cache_locations = [\n        Path.home() / \".cache\" / \"huggingface\" / \"hub\",\n        Path.home() / \".cache\" / \"huggingface\" / \"transformers\",\n    ]\n    \n    for cache_dir in cache_locations:\n        if cache_dir.exists():\n            # Look for directories containing the model name\n            for model_cache in cache_dir.glob(f\"*{safe_model_name}*\"):\n                try:\n                    if model_cache.is_dir():\n                        size = sum(f.stat().st_size for f in model_cache.rglob('*') if f.is_file()) / (1024**2)\n                        shutil.rmtree(model_cache)\n                        print(f\"üóëÔ∏è Cleared {model_name} cache: {size:.1f} MB freed\")\n                except Exception as e:\n                    print(f\"‚ùå Could not clear {model_cache}: {e}\")\n                    continue\n                    \ndef run_mains(test_embedding_models=[], test_text_generation_models=[]):\n    for embedding_model_index in test_embedding_models:\n        try:\n            main(mode=\"create\", embedding_model_index=embedding_model_index, text_generation_model_index=0)\n        except:\n            print(f\"failed to create db with {EMBEDDING_MODEL_OPTIONS[embedding_model_index]}\")\n            continue\n        for text_generation_model_index in test_text_generation_models:\n            try: \n                main(mode=\"quiz\", embedding_model_index=embedding_model_index, text_generation_model_index=text_generation_model_index)\n                print(f\"\")\n                # clear_specific_model_cache(EMBEDDING_MODEL_OPTIONS[embedding_model_index])\n            except:\n                print(f\"failed to run quiz with {EMBEDDING_MODEL_OPTIONS[embedding_model_index]} and {TEXT_GENERATION_MODEL_OPTIONS[text_generation_model_index]}\")\n                continue\n        if os.path.exists(\"chroma\"):\n            if os.path.exists(\"chroma\"):\n                shutil.rmtree(\"chroma\")\n","metadata":{"execution":{"iopub.status.busy":"2025-08-18T23:58:47.429782Z","iopub.execute_input":"2025-08-18T23:58:47.430003Z","iopub.status.idle":"2025-08-18T23:58:47.449067Z","shell.execute_reply.started":"2025-08-18T23:58:47.429984Z","shell.execute_reply":"2025-08-18T23:58:47.448392Z"},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":"list_models()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T23:58:47.449726Z","iopub.execute_input":"2025-08-18T23:58:47.449926Z","iopub.status.idle":"2025-08-18T23:58:47.468275Z","shell.execute_reply.started":"2025-08-18T23:58:47.449910Z","shell.execute_reply":"2025-08-18T23:58:47.467706Z"}},"outputs":[{"name":"stdout","text":"Available Embedding Models:\n  0: sentence-transformers/all-MiniLM-L6-v2 (huggingface)\n  1: sentence-transformers/all-mpnet-base-v2 (huggingface)\n  2: BAAI/bge-m3 (huggingface)\n  3: BAAI/bge-large-en (huggingface)\n  4: BAAI/bge-base-en-v1.5 (huggingface)\n  5: BAAI/bge-large-en-v1.5 (huggingface)\n  6: intfloat/e5-base-v2 (huggingface)\n  7: sentence-transformers/static-retrieval-mrl-en-v1 (huggingface)\n  8: sentence-transformers/all-MiniLM-L12-v2 (huggingface)\n  9: nomic-ai/nomic-embed-text-v1.5 (huggingface)\n  10: sentence-transformers/multi-qa-mpnet-base-dot-v1 (huggingface)\n  11: sentence-transformers/multi-qa-mpnet-base-cos-v1 (huggingface)\n  12: hkunlp/instructor-large (huggingface)\n  13: hkunlp/instructor-xl (huggingface)\n\nAvailable Text Generation Models:\n  0: google/flan-t5-small\n  1: google/flan-t5-base\n  2: google/flan-t5-large\n  3: google/flan-t5-xl\n  4: tiiuae/falcon-7b\n  5: tiiuae/Falcon-H1-0.5B-Instruct\n  6: tiiuae/falcon-7b-instruct\n  7: HuggingFaceH4/zephyr-7b-beta\n  8: google/gemma-3-1b-it\n  9: google/gemma-2-2b\n  10: google/gemma-2-2b-it\n  11: meta-llama/Llama-3.1-8B-Instruct\n  12: meta-llama/Llama-3.2-3B-Instruct\n  13: meta-llama/Meta-Llama-3-8B-Instruct\n  14: meta-llama/Llama-3.2-1B\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"run_mains(\n    test_embedding_models=[i for i in range(len(EMBEDDING_MODEL_OPTIONS))],\n    test_text_generation_models=[i for i in range(len(TEXT_GENERATION_MODEL_OPTIONS))]\n)\n\n","metadata":{"execution":{"iopub.status.busy":"2025-08-18T23:59:41.716152Z","iopub.execute_input":"2025-08-18T23:59:41.716783Z","execution_failed":"2025-08-19T00:08:45.215Z"},"scrolled":true,"trusted":true},"outputs":[{"name":"stdout","text":"Using embedding model: sentence-transformers/all-MiniLM-L6-v2 (huggingface)\nUsing text generation model: google/flan-t5-small\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e5ddb6553f947788d4dcaa149ce835d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad903aa3c42d46229be4c30d9ebc1f8f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2309e0459f54ecf9477bee108def73f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8d96583470b453fba512ae382ea74b1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85010cfed4ea44a9b5aafb84aa14a85a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f0493b949da40218ee7fe49b712615b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a67b01fa98874f4dbdad3ed310691f87"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2eb142dcda5845d499cc7b50765014b7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa9b264d08664cb48751f2bfdb7078af"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0ecc212ac924e618637df09edc317ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f6e194721464343b1fc0ad05f66b1be"}},"metadata":{}},{"name":"stdout","text":"Initialized huggingface embedding model: sentence-transformers/all-MiniLM-L6-v2\nEmbedding model: sentence-transformers/all-MiniLM-L6-v2 (huggingface)\nfailed to create db with sentence-transformers/all-MiniLM-L6-v2\nUsing embedding model: sentence-transformers/all-mpnet-base-v2 (huggingface)\nUsing text generation model: google/flan-t5-small\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7bb975429914929bae5c40592d97be4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc5b16615cf4404da25327d8843a97cd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3ef19ec89964d2b83d3c1086948c375"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ccb3859f1f0c48b0a67182b34273f3ac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e361865825848b496d3193c172512c6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1567105b10364aebbff6e70f80e21d9f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"706f9757ea3d4593aecf213ced9ca9af"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d6df242721c463ea31afdde88db8230"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"033d74ff3dde4d50bc6fa44eb9ab7921"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"858b81e85599432c866aaae3502e7e95"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20188329b48d43c4bf4f45d95dfebd6c"}},"metadata":{}},{"name":"stdout","text":"Initialized huggingface embedding model: sentence-transformers/all-mpnet-base-v2\nEmbedding model: sentence-transformers/all-mpnet-base-v2 (huggingface)\nUsing embedding model: sentence-transformers/all-mpnet-base-v2 (huggingface)\nUsing text generation model: google/flan-t5-small\nRunning Alice in Wonderland quiz...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d43ed5fda66340f6bf2c0b8a7d8cf290"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/308M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3fd5b019ce6c468998e15d3c697be87c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3c10ae71ef14d99b22af23c6e17d237"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74788bda0e754ad1b61cb53a3bd8c732"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"589d7898fdf1427081eafe4ae5cd5067"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b66acdeec7940f89966a6dee097ab34"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b61e489c81c4e4b8ffd184d96e4a6fd"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\nToken indices sequence length is longer than the specified maximum sequence length for this model (671 > 512). Running this sequence through the model will result in indexing errors\n","output_type":"stream"},{"name":"stdout","text":"Initialized huggingface embedding model: sentence-transformers/all-mpnet-base-v2 with chat model : google/flan-t5-small\n","output_type":"stream"},{"name":"stderr","text":"You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n/tmp/ipykernel_192/793184139.py:159: UserWarning: Relevance scores must be between 0 and 1, got [(Document(id='35066cf7-7da2-47c1-9c44-dc002953ca5b', metadata={'source': '/kaggle/input/text-for-summarizing/books/alice_in_wonderland.md', 'start_index': 23538}, page_content='CHAPTER III. A Caucus-Race and a Long Tale\\n\\nThey were indeed a queer-looking party that assembled on the bank‚Äîthe birds with draggled feathers, the animals with their fur clinging close to them, and all dripping wet, cross, and uncomfortable.'), 0.1564937101524343), (Document(id='5333f2a3-67cc-4e68-8268-41c16acd5f80', metadata={'source': '/kaggle/input/text-for-summarizing/books/alice_in_wonderland.md', 'start_index': 26447}, page_content='‚ÄúWhat I was going to say,‚Äù said the Dodo in an offended tone, ‚Äúwas, that the best thing to get us dry would be a Caucus-race.‚Äù\\n\\n‚ÄúWhat is a Caucus-race?‚Äù said Alice; not that she wanted much to know, but the Dodo had paused as if it thought that somebody ought to speak, and no one else seemed inclined to say anything.\\n\\n‚ÄúWhy,‚Äù said the Dodo, ‚Äúthe best way to explain it is to do it.‚Äù (And, as you might like to try the thing yourself, some winter day, I will tell you how the Dodo managed it.)'), 0.15244820275126758), (Document(id='6058e6dd-d1c4-40ff-bc8f-a9a75411ff92', metadata={'source': '/kaggle/input/text-for-summarizing/books/alice_in_wonderland.md', 'start_index': 23275}, page_content='It was high time to go, for the pool was getting quite crowded with the birds and animals that had fallen into it: there were a Duck and a Dodo, a Lory and an Eaglet, and several other curious creatures. Alice led the way, and the whole party swam to the shore.\\n\\nCHAPTER III. A Caucus-Race and a Long Tale'), 0.018435723002512283), (Document(id='93e2f5f4-2b30-4c32-9ee1-56b7c3f5fc3c', metadata={'start_index': 160478, 'source': '/kaggle/input/text-for-summarizing/books/alice_in_wonderland.md'}, page_content='The Foundation is committed to complying with the laws regulating charities and charitable donations in all 50 states of the United States. Compliance requirements are not uniform and it takes a considerable effort, much paperwork and many fees to meet and keep up with these requirements. We do not solicit donations in locations where we have not received written confirmation of compliance. To SEND DONATIONS or determine the status of compliance for any particular state visit'), -0.10365408765208728), (Document(id='7761d628-6cb1-45fd-89c9-41d8b9d835d8', metadata={'start_index': 26942, 'source': '/kaggle/input/text-for-summarizing/books/alice_in_wonderland.md'}, page_content='First it marked out a race-course, in a sort of circle, (‚Äúthe exact shape doesn‚Äôt matter,‚Äù it said,) and then all the party were placed along the course, here and there. There was no ‚ÄúOne, two, three, and away,‚Äù but they began running when they liked, and left off when they liked, so that it was not easy to know when the race was over. However, when they had been running half an hour or so, and were quite dry again, the Dodo suddenly called out ‚ÄúThe race is over!‚Äù and they all crowded round it,'), -0.12569292761952466)]\n  results = self.db.similarity_search_with_relevance_scores(query, k=k)\n/tmp/ipykernel_192/793184139.py:159: UserWarning: Relevance scores must be between 0 and 1, got [(Document(id='5333f2a3-67cc-4e68-8268-41c16acd5f80', metadata={'start_index': 26447, 'source': '/kaggle/input/text-for-summarizing/books/alice_in_wonderland.md'}, page_content='‚ÄúWhat I was going to say,‚Äù said the Dodo in an offended tone, ‚Äúwas, that the best thing to get us dry would be a Caucus-race.‚Äù\\n\\n‚ÄúWhat is a Caucus-race?‚Äù said Alice; not that she wanted much to know, but the Dodo had paused as if it thought that somebody ought to speak, and no one else seemed inclined to say anything.\\n\\n‚ÄúWhy,‚Äù said the Dodo, ‚Äúthe best way to explain it is to do it.‚Äù (And, as you might like to try the thing yourself, some winter day, I will tell you how the Dodo managed it.)'), 0.3010023567606456), (Document(id='35066cf7-7da2-47c1-9c44-dc002953ca5b', metadata={'source': '/kaggle/input/text-for-summarizing/books/alice_in_wonderland.md', 'start_index': 23538}, page_content='CHAPTER III. A Caucus-Race and a Long Tale\\n\\nThey were indeed a queer-looking party that assembled on the bank‚Äîthe birds with draggled feathers, the animals with their fur clinging close to them, and all dripping wet, cross, and uncomfortable.'), 0.1888890423233628), (Document(id='6058e6dd-d1c4-40ff-bc8f-a9a75411ff92', metadata={'start_index': 23275, 'source': '/kaggle/input/text-for-summarizing/books/alice_in_wonderland.md'}, page_content='It was high time to go, for the pool was getting quite crowded with the birds and animals that had fallen into it: there were a Duck and a Dodo, a Lory and an Eaglet, and several other curious creatures. Alice led the way, and the whole party swam to the shore.\\n\\nCHAPTER III. A Caucus-Race and a Long Tale'), 0.04951868660450853), (Document(id='7761d628-6cb1-45fd-89c9-41d8b9d835d8', metadata={'source': '/kaggle/input/text-for-summarizing/books/alice_in_wonderland.md', 'start_index': 26942}, page_content='First it marked out a race-course, in a sort of circle, (‚Äúthe exact shape doesn‚Äôt matter,‚Äù it said,) and then all the party were placed along the course, here and there. There was no ‚ÄúOne, two, three, and away,‚Äù but they began running when they liked, and left off when they liked, so that it was not easy to know when the race was over. However, when they had been running half an hour or so, and were quite dry again, the Dodo suddenly called out ‚ÄúThe race is over!‚Äù and they all crowded round it,'), -0.08198791011918294), (Document(id='83f43db6-7bcd-4d65-9c3c-d2ebe550567e', metadata={'start_index': 27807, 'source': '/kaggle/input/text-for-summarizing/books/alice_in_wonderland.md'}, page_content='‚ÄúBut who is to give the prizes?‚Äù quite a chorus of voices asked.\\n\\n‚ÄúWhy, she, of course,‚Äù said the Dodo, pointing to Alice with one finger; and the whole party at once crowded round her, calling out in a confused way, ‚ÄúPrizes! Prizes!‚Äù\\n\\nAlice had no idea what to do, and in despair she put her hand in her pocket, and pulled out a box of comfits, (luckily the salt water had not got into it), and handed them round as prizes. There was exactly one a-piece, all round.'), -0.09112155365997876)]\n  results = self.db.similarity_search_with_relevance_scores(query, k=k)\n","output_type":"stream"},{"name":"stdout","text":"\nQuiz Summary:\nCorrect Answers: 9 / 90. Accuracy: 10.0%\n\n==================================================\n\nUsing embedding model: sentence-transformers/all-mpnet-base-v2 (huggingface)\nUsing text generation model: google/flan-t5-base\nRunning Alice in Wonderland quiz...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7c379e8716a4865ab33af723e0965ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a636744121d458596a79d507314b517"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fadf4b3c265d4207936063dbb784d786"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08b77c80928744b89f748222f697c3d5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ff57ab41aa74da9b32ec6d9ee6c6824"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9470420b37a3403eabbba2f7906772bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e253a5d76b34d65a17f80bd58076603"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\nToken indices sequence length is longer than the specified maximum sequence length for this model (671 > 512). Running this sequence through the model will result in indexing errors\n","output_type":"stream"},{"name":"stdout","text":"Initialized huggingface embedding model: sentence-transformers/all-mpnet-base-v2 with chat model : google/flan-t5-base\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_192/793184139.py:159: UserWarning: Relevance scores must be between 0 and 1, got [(Document(id='35066cf7-7da2-47c1-9c44-dc002953ca5b', metadata={'start_index': 23538, 'source': '/kaggle/input/text-for-summarizing/books/alice_in_wonderland.md'}, page_content='CHAPTER III. A Caucus-Race and a Long Tale\\n\\nThey were indeed a queer-looking party that assembled on the bank‚Äîthe birds with draggled feathers, the animals with their fur clinging close to them, and all dripping wet, cross, and uncomfortable.'), 0.1564937101524343), (Document(id='5333f2a3-67cc-4e68-8268-41c16acd5f80', metadata={'start_index': 26447, 'source': '/kaggle/input/text-for-summarizing/books/alice_in_wonderland.md'}, page_content='‚ÄúWhat I was going to say,‚Äù said the Dodo in an offended tone, ‚Äúwas, that the best thing to get us dry would be a Caucus-race.‚Äù\\n\\n‚ÄúWhat is a Caucus-race?‚Äù said Alice; not that she wanted much to know, but the Dodo had paused as if it thought that somebody ought to speak, and no one else seemed inclined to say anything.\\n\\n‚ÄúWhy,‚Äù said the Dodo, ‚Äúthe best way to explain it is to do it.‚Äù (And, as you might like to try the thing yourself, some winter day, I will tell you how the Dodo managed it.)'), 0.15244820275126758), (Document(id='6058e6dd-d1c4-40ff-bc8f-a9a75411ff92', metadata={'source': '/kaggle/input/text-for-summarizing/books/alice_in_wonderland.md', 'start_index': 23275}, page_content='It was high time to go, for the pool was getting quite crowded with the birds and animals that had fallen into it: there were a Duck and a Dodo, a Lory and an Eaglet, and several other curious creatures. Alice led the way, and the whole party swam to the shore.\\n\\nCHAPTER III. A Caucus-Race and a Long Tale'), 0.018435723002512283), (Document(id='93e2f5f4-2b30-4c32-9ee1-56b7c3f5fc3c', metadata={'start_index': 160478, 'source': '/kaggle/input/text-for-summarizing/books/alice_in_wonderland.md'}, page_content='The Foundation is committed to complying with the laws regulating charities and charitable donations in all 50 states of the United States. Compliance requirements are not uniform and it takes a considerable effort, much paperwork and many fees to meet and keep up with these requirements. We do not solicit donations in locations where we have not received written confirmation of compliance. To SEND DONATIONS or determine the status of compliance for any particular state visit'), -0.10365408765208728), (Document(id='7761d628-6cb1-45fd-89c9-41d8b9d835d8', metadata={'source': '/kaggle/input/text-for-summarizing/books/alice_in_wonderland.md', 'start_index': 26942}, page_content='First it marked out a race-course, in a sort of circle, (‚Äúthe exact shape doesn‚Äôt matter,‚Äù it said,) and then all the party were placed along the course, here and there. There was no ‚ÄúOne, two, three, and away,‚Äù but they began running when they liked, and left off when they liked, so that it was not easy to know when the race was over. However, when they had been running half an hour or so, and were quite dry again, the Dodo suddenly called out ‚ÄúThe race is over!‚Äù and they all crowded round it,'), -0.12569292761952466)]\n  results = self.db.similarity_search_with_relevance_scores(query, k=k)\n/tmp/ipykernel_192/793184139.py:159: UserWarning: Relevance scores must be between 0 and 1, got [(Document(id='5333f2a3-67cc-4e68-8268-41c16acd5f80', metadata={'source': '/kaggle/input/text-for-summarizing/books/alice_in_wonderland.md', 'start_index': 26447}, page_content='‚ÄúWhat I was going to say,‚Äù said the Dodo in an offended tone, ‚Äúwas, that the best thing to get us dry would be a Caucus-race.‚Äù\\n\\n‚ÄúWhat is a Caucus-race?‚Äù said Alice; not that she wanted much to know, but the Dodo had paused as if it thought that somebody ought to speak, and no one else seemed inclined to say anything.\\n\\n‚ÄúWhy,‚Äù said the Dodo, ‚Äúthe best way to explain it is to do it.‚Äù (And, as you might like to try the thing yourself, some winter day, I will tell you how the Dodo managed it.)'), 0.3010023567606456), (Document(id='35066cf7-7da2-47c1-9c44-dc002953ca5b', metadata={'source': '/kaggle/input/text-for-summarizing/books/alice_in_wonderland.md', 'start_index': 23538}, page_content='CHAPTER III. A Caucus-Race and a Long Tale\\n\\nThey were indeed a queer-looking party that assembled on the bank‚Äîthe birds with draggled feathers, the animals with their fur clinging close to them, and all dripping wet, cross, and uncomfortable.'), 0.1888890423233628), (Document(id='6058e6dd-d1c4-40ff-bc8f-a9a75411ff92', metadata={'start_index': 23275, 'source': '/kaggle/input/text-for-summarizing/books/alice_in_wonderland.md'}, page_content='It was high time to go, for the pool was getting quite crowded with the birds and animals that had fallen into it: there were a Duck and a Dodo, a Lory and an Eaglet, and several other curious creatures. Alice led the way, and the whole party swam to the shore.\\n\\nCHAPTER III. A Caucus-Race and a Long Tale'), 0.04951868660450853), (Document(id='7761d628-6cb1-45fd-89c9-41d8b9d835d8', metadata={'start_index': 26942, 'source': '/kaggle/input/text-for-summarizing/books/alice_in_wonderland.md'}, page_content='First it marked out a race-course, in a sort of circle, (‚Äúthe exact shape doesn‚Äôt matter,‚Äù it said,) and then all the party were placed along the course, here and there. There was no ‚ÄúOne, two, three, and away,‚Äù but they began running when they liked, and left off when they liked, so that it was not easy to know when the race was over. However, when they had been running half an hour or so, and were quite dry again, the Dodo suddenly called out ‚ÄúThe race is over!‚Äù and they all crowded round it,'), -0.08198791011918294), (Document(id='83f43db6-7bcd-4d65-9c3c-d2ebe550567e', metadata={'source': '/kaggle/input/text-for-summarizing/books/alice_in_wonderland.md', 'start_index': 27807}, page_content='‚ÄúBut who is to give the prizes?‚Äù quite a chorus of voices asked.\\n\\n‚ÄúWhy, she, of course,‚Äù said the Dodo, pointing to Alice with one finger; and the whole party at once crowded round her, calling out in a confused way, ‚ÄúPrizes! Prizes!‚Äù\\n\\nAlice had no idea what to do, and in despair she put her hand in her pocket, and pulled out a box of comfits, (luckily the salt water had not got into it), and handed them round as prizes. There was exactly one a-piece, all round.'), -0.09112155365997876)]\n  results = self.db.similarity_search_with_relevance_scores(query, k=k)\n","output_type":"stream"},{"name":"stdout","text":"\nQuiz Summary:\nCorrect Answers: 35 / 90. Accuracy: 38.9%\n\n==================================================\n\nUsing embedding model: sentence-transformers/all-mpnet-base-v2 (huggingface)\nUsing text generation model: google/flan-t5-large\nRunning Alice in Wonderland quiz...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/662 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c75136b6e65f4407b9b7f42f81b9a220"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/3.13G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0ced924e8f64ba19779049d6d85d0f6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d6acba1a2f94d7f939746fe9b6e9e37"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8b05137066240e5bbb47252e5ad0616"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c77d4804d9df4539a355de2643ce1708"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec6aaad1ad31484f86af62d4388cbc8c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d31676532bdc477e8c14f884f5f4456e"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\nToken indices sequence length is longer than the specified maximum sequence length for this model (671 > 512). Running this sequence through the model will result in indexing errors\n","output_type":"stream"},{"name":"stdout","text":"Initialized huggingface embedding model: sentence-transformers/all-mpnet-base-v2 with chat model : google/flan-t5-large\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_192/793184139.py:159: UserWarning: Relevance scores must be between 0 and 1, got [(Document(id='35066cf7-7da2-47c1-9c44-dc002953ca5b', metadata={'source': '/kaggle/input/text-for-summarizing/books/alice_in_wonderland.md', 'start_index': 23538}, page_content='CHAPTER III. A Caucus-Race and a Long Tale\\n\\nThey were indeed a queer-looking party that assembled on the bank‚Äîthe birds with draggled feathers, the animals with their fur clinging close to them, and all dripping wet, cross, and uncomfortable.'), 0.1564937101524343), (Document(id='5333f2a3-67cc-4e68-8268-41c16acd5f80', metadata={'source': '/kaggle/input/text-for-summarizing/books/alice_in_wonderland.md', 'start_index': 26447}, page_content='‚ÄúWhat I was going to say,‚Äù said the Dodo in an offended tone, ‚Äúwas, that the best thing to get us dry would be a Caucus-race.‚Äù\\n\\n‚ÄúWhat is a Caucus-race?‚Äù said Alice; not that she wanted much to know, but the Dodo had paused as if it thought that somebody ought to speak, and no one else seemed inclined to say anything.\\n\\n‚ÄúWhy,‚Äù said the Dodo, ‚Äúthe best way to explain it is to do it.‚Äù (And, as you might like to try the thing yourself, some winter day, I will tell you how the Dodo managed it.)'), 0.15244820275126758), (Document(id='6058e6dd-d1c4-40ff-bc8f-a9a75411ff92', metadata={'start_index': 23275, 'source': '/kaggle/input/text-for-summarizing/books/alice_in_wonderland.md'}, page_content='It was high time to go, for the pool was getting quite crowded with the birds and animals that had fallen into it: there were a Duck and a Dodo, a Lory and an Eaglet, and several other curious creatures. Alice led the way, and the whole party swam to the shore.\\n\\nCHAPTER III. A Caucus-Race and a Long Tale'), 0.018435723002512283), (Document(id='93e2f5f4-2b30-4c32-9ee1-56b7c3f5fc3c', metadata={'start_index': 160478, 'source': '/kaggle/input/text-for-summarizing/books/alice_in_wonderland.md'}, page_content='The Foundation is committed to complying with the laws regulating charities and charitable donations in all 50 states of the United States. Compliance requirements are not uniform and it takes a considerable effort, much paperwork and many fees to meet and keep up with these requirements. We do not solicit donations in locations where we have not received written confirmation of compliance. To SEND DONATIONS or determine the status of compliance for any particular state visit'), -0.10365408765208728), (Document(id='7761d628-6cb1-45fd-89c9-41d8b9d835d8', metadata={'source': '/kaggle/input/text-for-summarizing/books/alice_in_wonderland.md', 'start_index': 26942}, page_content='First it marked out a race-course, in a sort of circle, (‚Äúthe exact shape doesn‚Äôt matter,‚Äù it said,) and then all the party were placed along the course, here and there. There was no ‚ÄúOne, two, three, and away,‚Äù but they began running when they liked, and left off when they liked, so that it was not easy to know when the race was over. However, when they had been running half an hour or so, and were quite dry again, the Dodo suddenly called out ‚ÄúThe race is over!‚Äù and they all crowded round it,'), -0.12569292761952466)]\n  results = self.db.similarity_search_with_relevance_scores(query, k=k)\n/tmp/ipykernel_192/793184139.py:159: UserWarning: Relevance scores must be between 0 and 1, got [(Document(id='5333f2a3-67cc-4e68-8268-41c16acd5f80', metadata={'source': '/kaggle/input/text-for-summarizing/books/alice_in_wonderland.md', 'start_index': 26447}, page_content='‚ÄúWhat I was going to say,‚Äù said the Dodo in an offended tone, ‚Äúwas, that the best thing to get us dry would be a Caucus-race.‚Äù\\n\\n‚ÄúWhat is a Caucus-race?‚Äù said Alice; not that she wanted much to know, but the Dodo had paused as if it thought that somebody ought to speak, and no one else seemed inclined to say anything.\\n\\n‚ÄúWhy,‚Äù said the Dodo, ‚Äúthe best way to explain it is to do it.‚Äù (And, as you might like to try the thing yourself, some winter day, I will tell you how the Dodo managed it.)'), 0.3010023567606456), (Document(id='35066cf7-7da2-47c1-9c44-dc002953ca5b', metadata={'source': '/kaggle/input/text-for-summarizing/books/alice_in_wonderland.md', 'start_index': 23538}, page_content='CHAPTER III. A Caucus-Race and a Long Tale\\n\\nThey were indeed a queer-looking party that assembled on the bank‚Äîthe birds with draggled feathers, the animals with their fur clinging close to them, and all dripping wet, cross, and uncomfortable.'), 0.1888890423233628), (Document(id='6058e6dd-d1c4-40ff-bc8f-a9a75411ff92', metadata={'source': '/kaggle/input/text-for-summarizing/books/alice_in_wonderland.md', 'start_index': 23275}, page_content='It was high time to go, for the pool was getting quite crowded with the birds and animals that had fallen into it: there were a Duck and a Dodo, a Lory and an Eaglet, and several other curious creatures. Alice led the way, and the whole party swam to the shore.\\n\\nCHAPTER III. A Caucus-Race and a Long Tale'), 0.04951868660450853), (Document(id='7761d628-6cb1-45fd-89c9-41d8b9d835d8', metadata={'start_index': 26942, 'source': '/kaggle/input/text-for-summarizing/books/alice_in_wonderland.md'}, page_content='First it marked out a race-course, in a sort of circle, (‚Äúthe exact shape doesn‚Äôt matter,‚Äù it said,) and then all the party were placed along the course, here and there. There was no ‚ÄúOne, two, three, and away,‚Äù but they began running when they liked, and left off when they liked, so that it was not easy to know when the race was over. However, when they had been running half an hour or so, and were quite dry again, the Dodo suddenly called out ‚ÄúThe race is over!‚Äù and they all crowded round it,'), -0.08198791011918294), (Document(id='83f43db6-7bcd-4d65-9c3c-d2ebe550567e', metadata={'source': '/kaggle/input/text-for-summarizing/books/alice_in_wonderland.md', 'start_index': 27807}, page_content='‚ÄúBut who is to give the prizes?‚Äù quite a chorus of voices asked.\\n\\n‚ÄúWhy, she, of course,‚Äù said the Dodo, pointing to Alice with one finger; and the whole party at once crowded round her, calling out in a confused way, ‚ÄúPrizes! Prizes!‚Äù\\n\\nAlice had no idea what to do, and in despair she put her hand in her pocket, and pulled out a box of comfits, (luckily the salt water had not got into it), and handed them round as prizes. There was exactly one a-piece, all round.'), -0.09112155365997876)]\n  results = self.db.similarity_search_with_relevance_scores(query, k=k)\n","output_type":"stream"},{"name":"stdout","text":"\nQuiz Summary:\nCorrect Answers: 42 / 90. Accuracy: 46.7%\n\n==================================================\n\nUsing embedding model: sentence-transformers/all-mpnet-base-v2 (huggingface)\nUsing text generation model: google/flan-t5-xl\nRunning Alice in Wonderland quiz...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d75a667f89324dae83a8df1d1422549f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d90f03df1d8485ca12252481c4e34b7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c5339fa8eec46e5962a5209e1c19c5b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/9.45G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9b8825db21842f2977c221810c74751"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/1.95G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db184bd5943c4876b8c8f72c7f7e4d5a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f69a620db154a798f9f0eb99dce5752"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ed3ef2b65504a91903f9377a5df887a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"618f7f6d521e4bc3832731ae90a8b1a1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"edbc200c073f4d31bfc4c8d28946573b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7fd99b0376484bda899304e7d5479fa3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff51a742d9d64b21a67a9999aa9a3870"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\nToken indices sequence length is longer than the specified maximum sequence length for this model (671 > 512). Running this sequence through the model will result in indexing errors\n","output_type":"stream"},{"name":"stdout","text":"Initialized huggingface embedding model: sentence-transformers/all-mpnet-base-v2 with chat model : google/flan-t5-xl\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_192/793184139.py:159: UserWarning: Relevance scores must be between 0 and 1, got [(Document(id='35066cf7-7da2-47c1-9c44-dc002953ca5b', metadata={'start_index': 23538, 'source': '/kaggle/input/text-for-summarizing/books/alice_in_wonderland.md'}, page_content='CHAPTER III. A Caucus-Race and a Long Tale\\n\\nThey were indeed a queer-looking party that assembled on the bank‚Äîthe birds with draggled feathers, the animals with their fur clinging close to them, and all dripping wet, cross, and uncomfortable.'), 0.1564937101524343), (Document(id='5333f2a3-67cc-4e68-8268-41c16acd5f80', metadata={'source': '/kaggle/input/text-for-summarizing/books/alice_in_wonderland.md', 'start_index': 26447}, page_content='‚ÄúWhat I was going to say,‚Äù said the Dodo in an offended tone, ‚Äúwas, that the best thing to get us dry would be a Caucus-race.‚Äù\\n\\n‚ÄúWhat is a Caucus-race?‚Äù said Alice; not that she wanted much to know, but the Dodo had paused as if it thought that somebody ought to speak, and no one else seemed inclined to say anything.\\n\\n‚ÄúWhy,‚Äù said the Dodo, ‚Äúthe best way to explain it is to do it.‚Äù (And, as you might like to try the thing yourself, some winter day, I will tell you how the Dodo managed it.)'), 0.15244820275126758), (Document(id='6058e6dd-d1c4-40ff-bc8f-a9a75411ff92', metadata={'source': '/kaggle/input/text-for-summarizing/books/alice_in_wonderland.md', 'start_index': 23275}, page_content='It was high time to go, for the pool was getting quite crowded with the birds and animals that had fallen into it: there were a Duck and a Dodo, a Lory and an Eaglet, and several other curious creatures. Alice led the way, and the whole party swam to the shore.\\n\\nCHAPTER III. A Caucus-Race and a Long Tale'), 0.018435723002512283), (Document(id='93e2f5f4-2b30-4c32-9ee1-56b7c3f5fc3c', metadata={'start_index': 160478, 'source': '/kaggle/input/text-for-summarizing/books/alice_in_wonderland.md'}, page_content='The Foundation is committed to complying with the laws regulating charities and charitable donations in all 50 states of the United States. Compliance requirements are not uniform and it takes a considerable effort, much paperwork and many fees to meet and keep up with these requirements. We do not solicit donations in locations where we have not received written confirmation of compliance. To SEND DONATIONS or determine the status of compliance for any particular state visit'), -0.10365408765208728), (Document(id='7761d628-6cb1-45fd-89c9-41d8b9d835d8', metadata={'start_index': 26942, 'source': '/kaggle/input/text-for-summarizing/books/alice_in_wonderland.md'}, page_content='First it marked out a race-course, in a sort of circle, (‚Äúthe exact shape doesn‚Äôt matter,‚Äù it said,) and then all the party were placed along the course, here and there. There was no ‚ÄúOne, two, three, and away,‚Äù but they began running when they liked, and left off when they liked, so that it was not easy to know when the race was over. However, when they had been running half an hour or so, and were quite dry again, the Dodo suddenly called out ‚ÄúThe race is over!‚Äù and they all crowded round it,'), -0.12569292761952466)]\n  results = self.db.similarity_search_with_relevance_scores(query, k=k)\n/tmp/ipykernel_192/793184139.py:159: UserWarning: Relevance scores must be between 0 and 1, got [(Document(id='5333f2a3-67cc-4e68-8268-41c16acd5f80', metadata={'start_index': 26447, 'source': '/kaggle/input/text-for-summarizing/books/alice_in_wonderland.md'}, page_content='‚ÄúWhat I was going to say,‚Äù said the Dodo in an offended tone, ‚Äúwas, that the best thing to get us dry would be a Caucus-race.‚Äù\\n\\n‚ÄúWhat is a Caucus-race?‚Äù said Alice; not that she wanted much to know, but the Dodo had paused as if it thought that somebody ought to speak, and no one else seemed inclined to say anything.\\n\\n‚ÄúWhy,‚Äù said the Dodo, ‚Äúthe best way to explain it is to do it.‚Äù (And, as you might like to try the thing yourself, some winter day, I will tell you how the Dodo managed it.)'), 0.3010023567606456), (Document(id='35066cf7-7da2-47c1-9c44-dc002953ca5b', metadata={'start_index': 23538, 'source': '/kaggle/input/text-for-summarizing/books/alice_in_wonderland.md'}, page_content='CHAPTER III. A Caucus-Race and a Long Tale\\n\\nThey were indeed a queer-looking party that assembled on the bank‚Äîthe birds with draggled feathers, the animals with their fur clinging close to them, and all dripping wet, cross, and uncomfortable.'), 0.1888890423233628), (Document(id='6058e6dd-d1c4-40ff-bc8f-a9a75411ff92', metadata={'source': '/kaggle/input/text-for-summarizing/books/alice_in_wonderland.md', 'start_index': 23275}, page_content='It was high time to go, for the pool was getting quite crowded with the birds and animals that had fallen into it: there were a Duck and a Dodo, a Lory and an Eaglet, and several other curious creatures. Alice led the way, and the whole party swam to the shore.\\n\\nCHAPTER III. A Caucus-Race and a Long Tale'), 0.04951868660450853), (Document(id='7761d628-6cb1-45fd-89c9-41d8b9d835d8', metadata={'source': '/kaggle/input/text-for-summarizing/books/alice_in_wonderland.md', 'start_index': 26942}, page_content='First it marked out a race-course, in a sort of circle, (‚Äúthe exact shape doesn‚Äôt matter,‚Äù it said,) and then all the party were placed along the course, here and there. There was no ‚ÄúOne, two, three, and away,‚Äù but they began running when they liked, and left off when they liked, so that it was not easy to know when the race was over. However, when they had been running half an hour or so, and were quite dry again, the Dodo suddenly called out ‚ÄúThe race is over!‚Äù and they all crowded round it,'), -0.08198791011918294), (Document(id='83f43db6-7bcd-4d65-9c3c-d2ebe550567e', metadata={'start_index': 27807, 'source': '/kaggle/input/text-for-summarizing/books/alice_in_wonderland.md'}, page_content='‚ÄúBut who is to give the prizes?‚Äù quite a chorus of voices asked.\\n\\n‚ÄúWhy, she, of course,‚Äù said the Dodo, pointing to Alice with one finger; and the whole party at once crowded round her, calling out in a confused way, ‚ÄúPrizes! Prizes!‚Äù\\n\\nAlice had no idea what to do, and in despair she put her hand in her pocket, and pulled out a box of comfits, (luckily the salt water had not got into it), and handed them round as prizes. There was exactly one a-piece, all round.'), -0.09112155365997876)]\n  results = self.db.similarity_search_with_relevance_scores(query, k=k)\n","output_type":"stream"},{"name":"stdout","text":"\nQuiz Summary:\nCorrect Answers: 62 / 90. Accuracy: 68.9%\n\n==================================================\n\nUsing embedding model: sentence-transformers/all-mpnet-base-v2 (huggingface)\nUsing text generation model: tiiuae/falcon-7b\nRunning Alice in Wonderland quiz...\n","output_type":"stream"},{"name":"stderr","text":"Device set to use cuda:0\nToken indices sequence length is longer than the specified maximum sequence length for this model (671 > 512). Running this sequence through the model will result in indexing errors\n","output_type":"stream"},{"name":"stdout","text":"Initialized huggingface embedding model: sentence-transformers/all-mpnet-base-v2 with chat model : tiiuae/falcon-7b\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_192/793184139.py:159: UserWarning: Relevance scores must be between 0 and 1, got [(Document(id='35066cf7-7da2-47c1-9c44-dc002953ca5b', metadata={'start_index': 23538, 'source': '/kaggle/input/text-for-summarizing/books/alice_in_wonderland.md'}, page_content='CHAPTER III. A Caucus-Race and a Long Tale\\n\\nThey were indeed a queer-looking party that assembled on the bank‚Äîthe birds with draggled feathers, the animals with their fur clinging close to them, and all dripping wet, cross, and uncomfortable.'), 0.1564937101524343), (Document(id='5333f2a3-67cc-4e68-8268-41c16acd5f80', metadata={'source': '/kaggle/input/text-for-summarizing/books/alice_in_wonderland.md', 'start_index': 26447}, page_content='‚ÄúWhat I was going to say,‚Äù said the Dodo in an offended tone, ‚Äúwas, that the best thing to get us dry would be a Caucus-race.‚Äù\\n\\n‚ÄúWhat is a Caucus-race?‚Äù said Alice; not that she wanted much to know, but the Dodo had paused as if it thought that somebody ought to speak, and no one else seemed inclined to say anything.\\n\\n‚ÄúWhy,‚Äù said the Dodo, ‚Äúthe best way to explain it is to do it.‚Äù (And, as you might like to try the thing yourself, some winter day, I will tell you how the Dodo managed it.)'), 0.15244820275126758), (Document(id='6058e6dd-d1c4-40ff-bc8f-a9a75411ff92', metadata={'source': '/kaggle/input/text-for-summarizing/books/alice_in_wonderland.md', 'start_index': 23275}, page_content='It was high time to go, for the pool was getting quite crowded with the birds and animals that had fallen into it: there were a Duck and a Dodo, a Lory and an Eaglet, and several other curious creatures. Alice led the way, and the whole party swam to the shore.\\n\\nCHAPTER III. A Caucus-Race and a Long Tale'), 0.018435723002512283), (Document(id='93e2f5f4-2b30-4c32-9ee1-56b7c3f5fc3c', metadata={'start_index': 160478, 'source': '/kaggle/input/text-for-summarizing/books/alice_in_wonderland.md'}, page_content='The Foundation is committed to complying with the laws regulating charities and charitable donations in all 50 states of the United States. Compliance requirements are not uniform and it takes a considerable effort, much paperwork and many fees to meet and keep up with these requirements. We do not solicit donations in locations where we have not received written confirmation of compliance. To SEND DONATIONS or determine the status of compliance for any particular state visit'), -0.10365408765208728), (Document(id='7761d628-6cb1-45fd-89c9-41d8b9d835d8', metadata={'source': '/kaggle/input/text-for-summarizing/books/alice_in_wonderland.md', 'start_index': 26942}, page_content='First it marked out a race-course, in a sort of circle, (‚Äúthe exact shape doesn‚Äôt matter,‚Äù it said,) and then all the party were placed along the course, here and there. There was no ‚ÄúOne, two, three, and away,‚Äù but they began running when they liked, and left off when they liked, so that it was not easy to know when the race was over. However, when they had been running half an hour or so, and were quite dry again, the Dodo suddenly called out ‚ÄúThe race is over!‚Äù and they all crowded round it,'), -0.12569292761952466)]\n  results = self.db.similarity_search_with_relevance_scores(query, k=k)\n/tmp/ipykernel_192/793184139.py:159: UserWarning: Relevance scores must be between 0 and 1, got [(Document(id='5333f2a3-67cc-4e68-8268-41c16acd5f80', metadata={'source': '/kaggle/input/text-for-summarizing/books/alice_in_wonderland.md', 'start_index': 26447}, page_content='‚ÄúWhat I was going to say,‚Äù said the Dodo in an offended tone, ‚Äúwas, that the best thing to get us dry would be a Caucus-race.‚Äù\\n\\n‚ÄúWhat is a Caucus-race?‚Äù said Alice; not that she wanted much to know, but the Dodo had paused as if it thought that somebody ought to speak, and no one else seemed inclined to say anything.\\n\\n‚ÄúWhy,‚Äù said the Dodo, ‚Äúthe best way to explain it is to do it.‚Äù (And, as you might like to try the thing yourself, some winter day, I will tell you how the Dodo managed it.)'), 0.3010023567606456), (Document(id='35066cf7-7da2-47c1-9c44-dc002953ca5b', metadata={'start_index': 23538, 'source': '/kaggle/input/text-for-summarizing/books/alice_in_wonderland.md'}, page_content='CHAPTER III. A Caucus-Race and a Long Tale\\n\\nThey were indeed a queer-looking party that assembled on the bank‚Äîthe birds with draggled feathers, the animals with their fur clinging close to them, and all dripping wet, cross, and uncomfortable.'), 0.1888890423233628), (Document(id='6058e6dd-d1c4-40ff-bc8f-a9a75411ff92', metadata={'source': '/kaggle/input/text-for-summarizing/books/alice_in_wonderland.md', 'start_index': 23275}, page_content='It was high time to go, for the pool was getting quite crowded with the birds and animals that had fallen into it: there were a Duck and a Dodo, a Lory and an Eaglet, and several other curious creatures. Alice led the way, and the whole party swam to the shore.\\n\\nCHAPTER III. A Caucus-Race and a Long Tale'), 0.04951868660450853), (Document(id='7761d628-6cb1-45fd-89c9-41d8b9d835d8', metadata={'start_index': 26942, 'source': '/kaggle/input/text-for-summarizing/books/alice_in_wonderland.md'}, page_content='First it marked out a race-course, in a sort of circle, (‚Äúthe exact shape doesn‚Äôt matter,‚Äù it said,) and then all the party were placed along the course, here and there. There was no ‚ÄúOne, two, three, and away,‚Äù but they began running when they liked, and left off when they liked, so that it was not easy to know when the race was over. However, when they had been running half an hour or so, and were quite dry again, the Dodo suddenly called out ‚ÄúThe race is over!‚Äù and they all crowded round it,'), -0.08198791011918294), (Document(id='83f43db6-7bcd-4d65-9c3c-d2ebe550567e', metadata={'source': '/kaggle/input/text-for-summarizing/books/alice_in_wonderland.md', 'start_index': 27807}, page_content='‚ÄúBut who is to give the prizes?‚Äù quite a chorus of voices asked.\\n\\n‚ÄúWhy, she, of course,‚Äù said the Dodo, pointing to Alice with one finger; and the whole party at once crowded round her, calling out in a confused way, ‚ÄúPrizes! Prizes!‚Äù\\n\\nAlice had no idea what to do, and in despair she put her hand in her pocket, and pulled out a box of comfits, (luckily the salt water had not got into it), and handed them round as prizes. There was exactly one a-piece, all round.'), -0.09112155365997876)]\n  results = self.db.similarity_search_with_relevance_scores(query, k=k)\n","output_type":"stream"},{"name":"stdout","text":"\nQuiz Summary:\nCorrect Answers: 42 / 90. Accuracy: 46.7%\n\n==================================================\n\nUsing embedding model: sentence-transformers/all-mpnet-base-v2 (huggingface)\nUsing text generation model: tiiuae/Falcon-H1-0.5B-Instruct\nRunning Alice in Wonderland quiz...\n","output_type":"stream"},{"name":"stderr","text":"Device set to use cuda:0\nToken indices sequence length is longer than the specified maximum sequence length for this model (671 > 512). Running this sequence through the model will result in indexing errors\n","output_type":"stream"},{"name":"stdout","text":"Initialized huggingface embedding model: sentence-transformers/all-mpnet-base-v2 with chat model : tiiuae/Falcon-H1-0.5B-Instruct\nfailed to run quiz with sentence-transformers/all-mpnet-base-v2 and tiiuae/Falcon-H1-0.5B-Instruct\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"model_response_directory = f\"/kaggle/working/quiz_results\"\nfor model_response_fp in os.listdir(model_response_directory):\n    avg_relevance_sources = []\n    count = 0\n    num_questions = 0\n    with open(os.path.join(model_response_directory, model_response_fp), \"r\") as f:\n        model_responses = json.load(f)\n        for response in model_responses:\n            if response[\"is_correct\"] == True:\n                count += 1\n            num_questions += 1\n            avg_relevance_sources.append(response[\"avg relevance sources\"])\n    print(f\"Model: {model_response_fp}, Correct: {count}/{num_questions}, Avg Relevance: {sum(avg_relevance_sources) / len(avg_relevance_sources) if avg_relevance_sources else 0}\")\n                ","metadata":{"execution":{"execution_failed":"2025-08-19T00:08:45.216Z"},"scrolled":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}